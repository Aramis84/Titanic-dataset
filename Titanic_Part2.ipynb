{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset Part 2 : Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "\n",
    "data_raw = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass                           Name     Sex  Age  \\\n",
       "5             6         0       3               Moran, Mr. James    male  NaN   \n",
       "17           18         1       2   Williams, Mr. Charles Eugene    male  NaN   \n",
       "19           20         1       3        Masselmani, Mrs. Fatima  female  NaN   \n",
       "26           27         0       3        Emir, Mr. Farred Chehab    male  NaN   \n",
       "28           29         1       3  O'Dwyer, Miss. Ellen \"Nellie\"  female  NaN   \n",
       "\n",
       "    SibSp  Parch  Ticket     Fare Cabin Embarked  \n",
       "5       0      0  330877   8.4583   NaN        Q  \n",
       "17      0      0  244373  13.0000   NaN        S  \n",
       "19      0      0    2649   7.2250   NaN        C  \n",
       "26      0      0    2631   7.2250   NaN        C  \n",
       "28      0      0  330959   7.8792   NaN        Q  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking care of missing values\n",
    "# Columns with missing values\n",
    "# Age, Embarked, Cabin\n",
    "\n",
    "# Age\n",
    "# subset of rows where age is missing\n",
    "data_raw[data_raw['Age'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1d987b38>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEPCAYAAABBUX+lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJakRBl+SGvH/uXZ4vZQ5ZgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d579e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can see the age distribution between passenger classes\n",
    "age_med = list(data_raw['Age'].groupby(data_raw['Pclass']).median())\n",
    "Q1 = data_raw['Age'].groupby(data_raw['Pclass']).quantile(0.25)\n",
    "Q3 = data_raw['Age'].groupby(data_raw['Pclass']).quantile(0.75)\n",
    "age_iqr = list(Q3-Q1)\n",
    "\n",
    "ind = np.arange(len(age_med))\n",
    "width = 0.35\n",
    "plt.bar(ind, age_med, width, color = 'indianred', yerr = age_iqr)\n",
    "plt.xticks(ind,['1','2','3'])\n",
    "plt.xlabel('Pclass')\n",
    "plt.ylabel('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sayandeep\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# We will replace missing age values based on the class of ticket of the passenger\n",
    "\n",
    "#lets make a copy of the original dataset\n",
    "\n",
    "data_work = data_raw.copy()\n",
    "class_age = {1: age_med[0], 2: age_med[1], 3: age_med[2]}\n",
    "data_work['Age'][data_work['Age'].isnull()] = data_work['Pclass'][data_work['Age'].isnull()].map(class_age)\n",
    "data_work.info()\n",
    "# we see that the null values in the Age column are gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "C    168\n",
       "Q     77\n",
       "S    644\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embarked\n",
    "# lets see which was the most common port of departure\n",
    "\n",
    "data_work['PassengerId'].groupby(data_work['Embarked']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       891 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# We will therefore replace missing port of embarkation as S\n",
    "data_work['Embarked'] = data_work['Embarked'].fillna('S')\n",
    "data_work.info()\n",
    "# Embarked column has no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 203 entries, 1 to 889\n",
      "Data columns (total 1 columns):\n",
      "Decks    203 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       891 non-null object\n",
      "Decks          203 non-null object\n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 97.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cabin\n",
    "# We will fill up missing cabin values (actually deck values) by comparing with the price.\n",
    "\n",
    "# lets create a column called 'Decks' that will provide the deck level for each passenger based on the cabin number\n",
    "temp_df = data_work['Cabin'].dropna()\n",
    "temp_df.head()\n",
    "decks = []\n",
    "index = []\n",
    "for ind, val in zip(temp_df.index.values, temp_df): #recording the index labels, this will be useful for dataframe concatenation\n",
    "    decks.append(val[0])\n",
    "    index.append(ind)\n",
    "\n",
    "deck_df = pd.DataFrame(decks, index = index) \n",
    "deck_df.columns = ['Decks'] #giving a name to the column\n",
    "deck_df = deck_df[deck_df['Decks'] !='T'] \n",
    "deck_df.info()\n",
    "\n",
    "data_temp = pd.concat([data_work,deck_df], axis = 1) # concat function automatically aligns rows with same indices. \n",
    "data_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Decks</th>\n",
       "      <th>No. of Cabins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Decks  No. of Cabins  \n",
       "0      0         A/5 21171   7.2500   NaN        S   NaN            NaN  \n",
       "1      0          PC 17599  71.2833   C85        C     C              1  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S   NaN            NaN  \n",
       "3      0            113803  53.1000  C123        S     C              1  \n",
       "4      0            373450   8.0500   NaN        S   NaN            NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For all the non- null values under 'Cabin', we need to see how many cabins were booked and divide the fare price by the \n",
    "# number of cabins to estimate the average price of a cabin based on the deck level\n",
    "\n",
    "data_nonnull_cabin = data_temp[data_temp['Cabin'].notnull()]\n",
    "def length(x):\n",
    "    temp = x.split(' ')\n",
    "    return len(temp)\n",
    "\n",
    "Cabin = data_nonnull_cabin['Cabin']\n",
    "num_of_cabins = map(length, list(Cabin))\n",
    "\n",
    "no_cabins_df = pd.DataFrame(num_of_cabins, index = data_nonnull_cabin.index.values)\n",
    "no_cabins_df.columns = ['No. of Cabins']\n",
    "\n",
    "data_temp = pd.concat([data_temp,no_cabins_df], axis = 1)\n",
    "data_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Decks</th>\n",
       "      <th>No. of Cabins</th>\n",
       "      <th>Fare per cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Decks  No. of Cabins  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S   NaN            NaN   \n",
       "1      0          PC 17599  71.2833   C85        C     C              1   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S   NaN            NaN   \n",
       "3      0            113803  53.1000  C123        S     C              1   \n",
       "4      0            373450   8.0500   NaN        S   NaN            NaN   \n",
       "\n",
       "   Fare per cabin  \n",
       "0             NaN  \n",
       "1         71.2833  \n",
       "2             NaN  \n",
       "3         53.1000  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temp['Fare per cabin'] = data_temp['Fare'].divide(data_temp['No. of Cabins'], axis = 'rows')\n",
    "data_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35.5,\n",
       " 69.299999999999997,\n",
       " 83.158299999999997,\n",
       " 52.554200000000002,\n",
       " 45.181249999999999,\n",
       " 11.17915,\n",
       " 13.581250000000001]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEPCAYAAACtCNj2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noiBJ6rMoSJL6LAqSpL7/Dw396RiYIRGeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8ea9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculating median fares as a function of deck levels\n",
    "fare_med = list(data_temp['Fare per cabin'].groupby(data_temp['Decks']).median())\n",
    "Q1 = data_temp['Fare per cabin'].groupby(data_temp['Decks']).quantile(0.25)\n",
    "Q3 = data_temp['Fare per cabin'].groupby(data_temp['Decks']).quantile(0.75)\n",
    "fare_iqr = list(Q3-Q1)\n",
    "\n",
    "ind = np.arange(len(fare_med))\n",
    "width = 0.35\n",
    "plt.bar(ind, fare_med, width, color = 'indianred', yerr = fare_iqr)\n",
    "plt.xticks(ind,['A','B','C','D','E','F','G'])\n",
    "plt.xlabel('Decks')\n",
    "plt.ylabel('Fare per cabin')\n",
    "fare_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sayandeep\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# We will fill up missing cabin values (actually deck values) by comparing with the price.\n",
    "fare_deck_map = {0:'A',1: 'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G'}\n",
    "\n",
    "prices = data_temp['Fare'][data_temp['Decks'].isnull()]\n",
    "def price_to_deck(prices, stats):\n",
    "    ind = [np.argmin(np.abs(price - stats)) for price in prices]\n",
    "    return ind\n",
    "\n",
    "ind = pd.Series(price_to_deck(prices, fare_med), index = prices.index.values)\n",
    "\n",
    "data_temp['Decks'][data_temp['Decks'].isnull()] = ind.map(fare_deck_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "PassengerId       891 non-null int64\n",
      "Survived          891 non-null int64\n",
      "Pclass            891 non-null int64\n",
      "Name              891 non-null object\n",
      "Sex               891 non-null object\n",
      "Age               891 non-null float64\n",
      "SibSp             891 non-null int64\n",
      "Parch             891 non-null int64\n",
      "Ticket            891 non-null object\n",
      "Fare              891 non-null float64\n",
      "Cabin             204 non-null object\n",
      "Embarked          891 non-null object\n",
      "Decks             891 non-null object\n",
      "No. of Cabins     204 non-null float64\n",
      "Fare per cabin    204 non-null float64\n",
      "dtypes: float64(4), int64(5), object(6)\n",
      "memory usage: 111.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_temp.info()\n",
    "# Now that all missing values have been populated, we will drop the temporary columns we created along the way. For example, \n",
    "# there is no way to fill up missing values of no.of cabins with the information we have. Also note that the Decks column now\n",
    "# provides information abou the deck levels. We do not need the 'Cabins' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Decks</th>\n",
       "      <th>No. of Cabins</th>\n",
       "      <th>Fare per cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Decks  No. of Cabins  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S     F            NaN   \n",
       "1      0          PC 17599  71.2833   C85        C     C              1   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S     F            NaN   \n",
       "3      0            113803  53.1000  C123        S     C              1   \n",
       "4      0            373450   8.0500   NaN        S     F            NaN   \n",
       "\n",
       "   Fare per cabin  \n",
       "0             NaN  \n",
       "1         71.2833  \n",
       "2             NaN  \n",
       "3         53.1000  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_modified = data_temp.copy()\n",
    "data_modified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data_modified['Cabin']\n",
    "del data_modified['Fare per cabin']\n",
    "del data_modified['No. of Cabins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Embarked       891 non-null object\n",
      "Decks          891 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_modified.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Embarked       891 non-null object\n",
      "Decks          891 non-null object\n",
      "Group Size     891 non-null object\n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 97.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Before we begin applying machine learning algorithms, we will add some new features to the dataset.\n",
    "# The group size : whether the passenger was alone or with family\n",
    "# Person category: whether the passenger was an adult (male/female) or a child\n",
    "\n",
    "data_modified['Group Size'] = data_modified['Parch'] + data_modified['SibSp']\n",
    "def alone(passenger):\n",
    "    grp_size = passenger\n",
    "    if grp_size>0:\n",
    "        return 'In group'\n",
    "    else:\n",
    "        return 'Alone'\n",
    "    \n",
    "data_modified['Group Size'] = data_modified['Group Size'].apply(alone)\n",
    "data_modified.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Decks</th>\n",
       "      <th>Group Size</th>\n",
       "      <th>Person Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>In group</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>In group</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>Alone</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>In group</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>Alone</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Embarked Decks Group Size Person Category  \n",
       "0      0         A/5 21171   7.2500        S     F   In group            male  \n",
       "1      0          PC 17599  71.2833        C     C   In group          female  \n",
       "2      0  STON/O2. 3101282   7.9250        S     F      Alone          female  \n",
       "3      0            113803  53.1000        S     C   In group          female  \n",
       "4      0            373450   8.0500        S     F      Alone            male  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pass_category(pass_det):\n",
    "    age, sex = pass_det\n",
    "    if age < 18:\n",
    "        return 'child'\n",
    "    else:\n",
    "        return sex\n",
    "    \n",
    "data_modified['Person Category'] = data_modified[['Age', 'Sex']].apply(pass_category, axis = 1)\n",
    "data_modified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will select some of the main features in the dataset. Some features such as SIbSp and Parch were combined to generate new\n",
    "# features. Hence we leave out the individual component features. Note we converted numerical features to categorial features. \n",
    "# This process generally results in more abstraction and as a result might be less accurate. The results that follow will be\n",
    "# heavily influenced on the choice of features and their type (numerical or categorical)\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Decks', 'Group Size','Person Category']\n",
    "X_raw = data_modified[features]\n",
    "y_raw = data_modified['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 5) (891, 3)\n"
     ]
    }
   ],
   "source": [
    "# Extracting categorical and numerical attributes\n",
    "X_raw_categorical = X_raw.select_dtypes(include  = ['object'])\n",
    "X_raw_numerical = X_raw.select_dtypes(include  = ['int64', 'float64'])\n",
    "print X_raw_categorical.shape, X_raw_numerical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891L, 5L) (891L, 3L)\n"
     ]
    }
   ],
   "source": [
    "X_raw_numerical_arr = X_raw_numerical.as_matrix()\n",
    "X_raw_categorical_arr = X_raw_categorical.as_matrix()\n",
    "# lets check the shapes of the arrays for sanity\n",
    "print X_raw_categorical_arr.shape, X_raw_numerical_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "num_operations = StandardScaler()\n",
    "cat_operations = LabelBinarizer()\n",
    "\n",
    "X_prepared = num_operations.fit_transform(X_raw_numerical_arr)\n",
    "for ind in range(X_raw_categorical_arr.shape[1]):\n",
    "    col = X_raw_categorical_arr[:,ind]\n",
    "    col_trans = cat_operations.fit_transform(col)\n",
    "    X_prepared = np.c_[X_prepared, col_trans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' We will use an ensemble of classifiers for the given task. In ensemble learning, bank of classifiers are trained for the same\n",
    "goal and the outputs of the  individual classifiers are combined to compute the final decision (class label). More the \n",
    "diversity between classifiers, better is the ensemble system. The ensemble system is more robust, mus less sensitive to input\n",
    "variations and most importantly much less prone to over-fitting. Diversity means each individual classifier learns something\n",
    "different from the other classifiers. Most easy way to introduce this diversity is by resampling the traning set and training\n",
    "the same classifier but with varying training sets. This is called \"Bagging\" or \"Bootsrap Aggregating\". In this exercise, we\n",
    "will introduce diversity by keeping the training set same but using completely different classifiers. Specifically we will use\n",
    "1. Stochastic Gradient Classifier, 2. Logistic Regression,  3. Support Vector Machine, 4. Randon Forest, 5. Naive Bayes', \n",
    "6. K-Nearest Neighbor.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891L, 18L), (891L,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use cross validation to evaluate the models. Also we will use gridsearch for hyper-parameter tuning. So let's import \n",
    "# the necessary modules.\n",
    "from __future__ import division\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = X_prepared\n",
    "y = y_raw.as_matrix()\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "{'learning_rate': 'constant', 'eta0': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  38 out of  45 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  45 out of  45 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Let us run a grid search and design the best classifier of each type with the best hyper-parameters\n",
    "# SGD Classifier\n",
    "param_grid = [{'learning_rate' : ['constant', 'optimal', 'invscaling'], 'eta0' : [0.1, 0.05, 0.01]}]\n",
    "sgd_clf = SGDClassifier(loss = 'log',random_state =1)\n",
    "gridsearch_sgd = GridSearchCV(sgd_clf, param_grid, cv = 5, n_jobs =4, verbose = 2)\n",
    "gridsearch_sgd.fit(X, y)\n",
    "best_sgd_clf = gridsearch_sgd.best_estimator_\n",
    "print gridsearch_sgd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "param_grid = [{'C' : [1,10,100,1000]}]\n",
    "lgr_clf = LogisticRegression(random_state = 1)\n",
    "gridsearch_lgr = GridSearchCV(lgr_clf, param_grid, cv = 5, n_jobs = 4, verbose = 2)\n",
    "gridsearch_lgr.fit(X, y)\n",
    "best_lgr_clf = gridsearch_lgr.best_estimator_\n",
    "print gridsearch_lgr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:   21.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'n_estimators': 100, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "param_grid = [{'n_estimators' : [10,100,300,500], 'max_depth': [3,5,8,10,15]}]\n",
    "raf_clf = RandomForestClassifier(random_state = 1)\n",
    "gridsearch_raf = GridSearchCV(raf_clf, param_grid, cv = 5, n_jobs = 4, verbose = 2)\n",
    "gridsearch_raf.fit(X,y)\n",
    "best_raf_clf = gridsearch_raf.best_estimator_\n",
    "print gridsearch_raf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes'\n",
    "nab_clf = GaussianNB()\n",
    "nab_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 170 out of 170 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 34 candidates, totalling 170 fits\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "param_grid = [{'kernel' : ['linear', 'rbf'], 'C' : [0.1, 1, 10, 100], 'gamma' : [0.001,0.01, 0.1, 0.5]},\\\n",
    "             {'kernel' : ['poly'],'degree': [2,3] }]\n",
    "svm_clf = SVC(random_state = 1)\n",
    "gridsearch_svm = GridSearchCV(svm_clf, param_grid, cv = 5, n_jobs =4 ,verbose = 2)\n",
    "gridsearch_svm.fit(X,y)\n",
    "best_svm_clf = gridsearch_svm.best_estimator_\n",
    "print gridsearch_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "{'n_neighbors': 5, 'metric': 'minkowski'}\n"
     ]
    }
   ],
   "source": [
    "# KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "\n",
    "V = np.cov(X.transpose())\n",
    "maha = DistanceMetric.get_metric('mahalanobis',V=V)\n",
    "\n",
    "\n",
    "param_grid = [{'n_neighbors' : [3,5,7,9], 'metric': ['minkowski', maha, 'euclidean'] }]\n",
    "knn_clf = KNeighborsClassifier()\n",
    "gridsearch_knn = GridSearchCV(knn_clf, param_grid, cv = 5, n_jobs = 4, verbose = 2)\n",
    "gridsearch_knn.fit(X,y)\n",
    "best_knn_clf = gridsearch_knn.best_estimator_\n",
    "print gridsearch_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 (+/- 0.0292) [SGD]\n",
      "Accuracy: 0.81 (+/- 0.0311) [Logistic Regression]\n",
      "Accuracy: 0.76 (+/- 0.0293) [Naive Bayes]\n",
      "Accuracy: 0.84 (+/- 0.0380) [Random Forest]\n",
      "Accuracy: 0.82 (+/- 0.0280) [Support Vector Machine]\n",
      "Accuracy: 0.81 (+/- 0.0258) [K-NN]\n",
      "Accuracy: 0.82 (+/- 0.0321) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# Now that we have 6 tuned classifiers, lets combine them and test the ensemble on the train set using cross validation\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ens_clf = VotingClassifier(estimators = [('sgd', best_sgd_clf) , ('lgr', best_lgr_clf), ('nab', nab_clf),\\\n",
    "                                        ('raf', best_raf_clf), ('svm', best_svm_clf), ('knn', best_knn_clf)])\n",
    "\n",
    "ens_clf.fit(X, y)\n",
    "classifier_list = [best_sgd_clf, best_lgr_clf, nab_clf, best_raf_clf, best_svm_clf, best_knn_clf, ens_clf]\n",
    "labels = ['SGD', 'Logistic Regression', 'Naive Bayes', 'Random Forest', 'Support Vector Machine', 'K-NN', 'Ensemble']\n",
    "weights = []\n",
    "for clf, label in zip(classifier_list, labels):\n",
    "    scores = cross_val_score(clf, X, y, cv = 10, scoring = 'accuracy')\n",
    "    temp  = np.log(scores.mean()/(1-scores.mean()))\n",
    "    weights.append(temp)\n",
    "    print 'Accuracy: %0.2f (+/- %0.4f) [%s]' %(scores.mean(), scores.std(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.75, True Detection: 0.75, False Alarm: 0.15  [SGD]\n",
      "F1-Score: 0.74, True Detection: 0.72, False Alarm: 0.14  [Logistic Regression]\n",
      "F1-Score: 0.69, True Detection: 0.75, False Alarm: 0.27  [Naive Bayes]\n",
      "F1-Score: 0.76, True Detection: 0.73, False Alarm: 0.11  [Random Forest]\n",
      "F1-Score: 0.74, True Detection: 0.67, False Alarm: 0.08  [Support Vector Machine]\n",
      "F1-Score: 0.73, True Detection: 0.71, False Alarm: 0.14  [K-NN]\n",
      "F1-Score: 0.75, True Detection: 0.71, False Alarm: 0.11  [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# Sometimes accuracy is not a good way to judge performance especially when distributions of classes are skewed. We will use a\n",
    "# more robust method, namely the confusion matrix.\n",
    "# To compute the confusion matrix, we need the predicted classes from all the classifiers and the ensemble.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "for clf, label in zip(classifier_list, labels):\n",
    "    y_pred = cross_val_predict(clf, X, y, cv = 5)\n",
    "    f1score = f1_score(y, y_pred)\n",
    "    pre_score = precision_score(y,y_pred)\n",
    "    rec_score = recall_score(y,y_pred)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    row_sums = conf_mat.sum(axis = 1, keepdims = True)\n",
    "    norm_conf_mat = conf_mat/row_sums\n",
    "    true_positive = norm_conf_mat[1,1]\n",
    "    false_alarm = norm_conf_mat[0,1]\n",
    "    print 'F1-Score: %0.2f, True Detection: %0.2f, False Alarm: %0.2f  [%s]' %(f1score, true_positive, false_alarm, label)\n",
    "    \n",
    "# Any non-zero value on the off-diagonal elements in the confusion matrix means there is an error. The top right is false alarm \n",
    "# or Type I error, and the bottom left is mis-detection or the Type II error. Consolidating the confusion matrix into one single\n",
    "# number is ieasier for us mortals to comprehend. We will use the predicted values to compute the F1 score which is the harmonic\n",
    "# mean of the precision and recall. Higher the F1 score (max is 1) better is the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 (+/- 0.0292) [SGD]\n",
      "Accuracy: 0.81 (+/- 0.0311) [Logistic Regression]\n",
      "Accuracy: 0.76 (+/- 0.0293) [Naive Bayes]\n",
      "Accuracy: 0.84 (+/- 0.0380) [Random Forest]\n",
      "Accuracy: 0.82 (+/- 0.0280) [Support Vector Machine]\n",
      "Accuracy: 0.81 (+/- 0.0258) [K-NN]\n",
      "Accuracy: 0.82 (+/- 0.0317) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# we will next try weighted majority voting which gives more trust to the better classifiers\n",
    "ens_clf_wt = VotingClassifier(estimators = [('sgd', best_sgd_clf) , ('lgr', best_lgr_clf), ('nab', nab_clf),\\\n",
    "                                        ('raf', best_raf_clf), ('svm', best_svm_clf), ('knn', best_knn_clf)], weights = weights[:-1])\n",
    "ens_clf_wt.fit(X, y)\n",
    "classifier_list = [best_sgd_clf, best_lgr_clf, nab_clf, best_raf_clf, best_svm_clf, best_knn_clf, ens_clf_wt]\n",
    "labels = ['SGD', 'Logistic Regression', 'Naive Bayes', 'Random Forest', 'Support Vector Machine', 'K-NN', 'Ensemble']\n",
    "for clf, label in zip(classifier_list, labels):\n",
    "    scores = cross_val_score(clf, X, y, cv = 10, scoring = 'accuracy')\n",
    "    print 'Accuracy: %0.2f (+/- %0.4f) [%s]' %(scores.mean(), scores.std(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:   10.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'activation': 'relu', 'hidden_layer_sizes': (50,)}\n"
     ]
    }
   ],
   "source": [
    "# lets try a simple neural net (multi-layer perceptron)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_grid = [{'activation' : ['relu', 'tanh'], 'hidden_layer_sizes' : [(100,),(50,),(100,50),(10,10),(20,10)]}]\n",
    "mlp_clf = MLPClassifier(max_iter = 1000, random_state = 42, learning_rate = 'adaptive')\n",
    "gridsearch_mlp = GridSearchCV(mlp_clf, param_grid, cv = 5, n_jobs = 4, verbose = 2)\n",
    "gridsearch_mlp.fit(X,y)\n",
    "best_mlp_clf = gridsearch_mlp.best_estimator_\n",
    "print gridsearch_mlp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 (+/- 0.0292) [SGD]\n",
      "Accuracy: 0.81 (+/- 0.0311) [Logistic Regression]\n",
      "Accuracy: 0.76 (+/- 0.0293) [Naive Bayes]\n",
      "Accuracy: 0.84 (+/- 0.0380) [Random Forest]\n",
      "Accuracy: 0.82 (+/- 0.0280) [Support Vector Machine]\n",
      "Accuracy: 0.81 (+/- 0.0258) [K-NN]\n",
      "Accuracy: 0.81 (+/- 0.0389) [MLP]\n",
      "Accuracy: 0.82 (+/- 0.0372) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "ens_clf = VotingClassifier(estimators = [('sgd', best_sgd_clf) , ('lgr', best_lgr_clf), ('nab', nab_clf),\\\n",
    "                                        ('raf', best_raf_clf), ('svm', best_svm_clf), ('knn', best_knn_clf),\\\n",
    "                                        ('mlp', best_mlp_clf)])\n",
    "\n",
    "ens_clf.fit(X, y)\n",
    "classifier_list = [best_sgd_clf, best_lgr_clf, nab_clf, best_raf_clf, best_svm_clf, best_knn_clf, best_mlp_clf, ens_clf]\n",
    "labels = ['SGD', 'Logistic Regression', 'Naive Bayes', 'Random Forest', 'Support Vector Machine', 'K-NN', 'MLP', 'Ensemble']\n",
    "weights = []\n",
    "for clf, label in zip(classifier_list, labels):\n",
    "    scores = cross_val_score(clf, X, y, cv = 10, scoring = 'accuracy')\n",
    "    temp  = np.log(scores.mean()/(1-scores.mean()))\n",
    "    weights.append(temp)\n",
    "    print 'Accuracy: %0.2f (+/- %0.4f) [%s]' %(scores.mean(), scores.std(), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will try another combination/fusion rule. This rule comes from the field of parallel decision fusion. The optimal decision\n",
    "# combination rule under certain conditions is a weighted sum of the individual classifier decisions compared to a threshold.\n",
    "# MOre details can be found in http://ieeexplore.ieee.org/document/4104179/\n",
    "\n",
    "def class_test_stat(y_pred, tp,fa):\n",
    "    a1 = tp/fa\n",
    "    a2 = (1-fa)/(1-tp)\n",
    "    y_pred[y_pred==0] = -1\n",
    "    wt_dec = []\n",
    "    for y in y_pred:\n",
    "        if y == 1:\n",
    "            wt_dec.append(np.log(a1)*y)\n",
    "        else:\n",
    "            wt_dec.append(np.log(a2)*y)\n",
    "    \n",
    "    return wt_dec\n",
    "classifier_list = [best_sgd_clf, best_lgr_clf, nab_clf, best_raf_clf, best_svm_clf, best_knn_clf, best_mlp_clf]\n",
    "labels = ['SGD', 'Logistic Regression', 'Naive Bayes', 'Random Forest', 'Support Vector Machine', 'K-NN', 'MLP']\n",
    "\n",
    "mega_list = []\n",
    "for clf, label in zip(classifier_list, labels):\n",
    "    y_pred = cross_val_predict(clf, X, y, cv = 5)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    row_sums = conf_mat.sum(axis = 1, keepdims = True)\n",
    "    norm_conf_mat = conf_mat/row_sums\n",
    "    true_positive = norm_conf_mat[1,1]\n",
    "    false_alarm = norm_conf_mat[0,1]\n",
    "    y_wt_pred = class_test_stat(y_pred, true_positive, false_alarm)\n",
    "    y_wt_pred = np.array(y_wt_pred).reshape(-1,1)\n",
    "    mega_list.append(y_wt_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891L, 7L)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_wt_pred = np.concatenate(mega_list, axis = 1)\n",
    "all_wt_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post fusion accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Fusion center predictions\n",
    "def fusion_center_pred(M):\n",
    "    row_sum = M.sum(axis=1, keepdims = True)\n",
    "    row_sum = row_sum.reshape(-1) # to change to 1D array\n",
    "    y_pred_fus = list((row_sum>0)*1)\n",
    "    return y_pred_fus\n",
    "\n",
    "y_pred_fus = fusion_center_pred(all_wt_pred)\n",
    "\n",
    "# Fusion center accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "fus_accuracy = accuracy_score(y,y_pred_fus)\n",
    "print 'Post fusion accuracy: %0.2f' %fus_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
